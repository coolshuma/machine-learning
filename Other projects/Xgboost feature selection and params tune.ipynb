{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Общее\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import datetime\n",
    "\n",
    "# Графики\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from pylab import rcParams\n",
    "import seaborn\n",
    "\n",
    "import telegram_send\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# featured_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check cnt of predict by label cl\n",
    "\n",
    "def count_class(true, pred, cl=1):\n",
    "    all_ones = 0\n",
    "    pred_ones = 0\n",
    "    for i in range(len(true)):\n",
    "        if true.iloc[i] == cl:\n",
    "            all_ones += 1\n",
    "            if pred[i] == cl:\n",
    "                pred_ones += 1\n",
    "    print('Classifier with this thres. assign to {} class:'.format(cl))\n",
    "    print('all_in_class = {}'.format(all_ones))\n",
    "    print('clf_pred = {}'.format(pred_ones))\n",
    "    print()\n",
    "\n",
    "    \n",
    "# Make oversampling for clf\n",
    "\n",
    "def oversampling(features, labels):\n",
    "    feat_to_add = features[labels == 1].copy()\n",
    "    labels_to_add = labels[labels == 1].copy()\n",
    "    steps = labels.shape[0] // labels_to_add.shape[0]\n",
    "    for i in range(steps):\n",
    "        np.append(features, feat_to_add)\n",
    "        labels.append(labels_to_add)\n",
    "    \n",
    "    diff = labels[labels == 0].shape[0] - labels[labels == 1].shape[0]\n",
    "    np.append(features, feat_to_add[:diff])\n",
    "    labels.append(labels_to_add[:diff])\n",
    "\n",
    "\n",
    "def make_classification(featured_data, labels, clf, scaler, test_size=0.25, \n",
    "                        show_feat_imp=None, make_cv=False, cv_folds = 5, \n",
    "                        prob_thres=0.5, show_class=0):\n",
    "    '''\n",
    "    Make classification by clf classifier.\n",
    "    \n",
    "    featured_data : features\n",
    "    labels : labels of classes\n",
    "    clf : classifier\n",
    "    show_feat_imp : show plot or dframe weights of features\n",
    "    make_cv : if True make cross-validation on cv_folds \n",
    "    prob_thres : probability threshold to classify object as 1 class\n",
    "    show_class : class to count in count_class func\n",
    "    '''\n",
    "    # Scale and Split\n",
    "    # featured_data = featured_data[featured_data.columns[compreh_good_feats]]\n",
    "    X = scaler.fit_transform(featured_data)\n",
    "    y = labels\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, shuffle=True, stratify=y)\n",
    "    oversampling(X_train, y_train)\n",
    "    \n",
    "     # Cross-validation\n",
    "    if make_cv:\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        cv_score = cross_val_score(clf, X, y, scoring='roc_auc', cv=cv)\n",
    "        print('AUC on CV =', cv_score)\n",
    "        print('Mean AUC on CV =', cv_score.mean())\n",
    "        telegram_send.send(messages=['Score on cv: ' + str(cv_score.mean()),], \n",
    "                   conf=r'C:\\Users\\shumilkinayu\\Documents\\tg_notification.conf')\n",
    "        \n",
    "    \n",
    "    # Clf fit\n",
    "    clf.fit(X_train, y_train)\n",
    "    print('----- Clf fitted! -----')\n",
    "    \n",
    "    \n",
    "    # Feature importance\n",
    "    if show_feat_imp == 'log_reg':\n",
    "        pd.DataFrame(index=featured_data.columns.values, data=clf.coef_.reshape([-1, 1])).sort_values(by=0).head()\n",
    "        \n",
    "    if show_feat_imp == 'xgb':\n",
    "        pd.DataFrame(index=featured_data.columns.values, data=clf.feature_importances_.reshape([-1, 1])).sort_values(by=0, ascending=False).head()\n",
    "        \n",
    "        # Xgb plot feature importance\n",
    "        fig, ax = plt.subplots(1, 1,figsize=(15, 45))\n",
    "        plot_importance(clf, ax)\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    # Metric on test\n",
    "    print('TEST:')\n",
    "    \n",
    "#     for prob_thres in [0.2, 0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "#         preds = list(map(lambda x: 1 if x[1] > prob_thres else 0, clf.predict_proba(X_test)))\n",
    "#         print('AUC =', roc_auc_score(y_test, preds))\n",
    "#         print('Thresh =', prob_thres)\n",
    "    \n",
    "    count_class(y_test, preds, show_class)\n",
    "\n",
    "    preds = clf.predict_proba(X_test)[:, 1]\n",
    "    print('AUC =', roc_auc_score(y_test, preds))\n",
    "    from sklearn.metrics import log_loss\n",
    "    fpr, tpr, thr = roc_curve(y_test, preds)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1], [0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    # Metric on train\n",
    "    print('TRAIN:')\n",
    "    preds = list(map(lambda x: 1 if x[1] > prob_thres else 0, clf.predict_proba(X_train)))\n",
    "    count_class(y_train, preds, show_class)\n",
    "\n",
    "    preds = clf.predict_proba(X_train)[:, 1]\n",
    "    print('AUC =', roc_auc_score(y_train, preds))\n",
    "    fpr, tpr, thr = roc_curve(y_train, preds)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1], [0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    print('ALL:')\n",
    "    preds = list(map(lambda x: 1 if x[1] > prob_thres else 0, clf.predict_proba(X)))\n",
    "    count_class(y, preds, show_class)\n",
    "    \n",
    "    preds = clf.predict_proba(X)[:, 1]\n",
    "    print('AUC =', roc_auc_score(y, preds))\n",
    "    fpr, tpr, thr = roc_curve(y, preds)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1], [0,1])\n",
    "    plt.show()\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_send.send(messages=['Classifier fit_predict began!',], \n",
    "                   conf=r'C:\\Users\\shumilkinayu\\Documents\\tg_notification.conf')\n",
    "clf = XGBClassifier()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# params = {'base_score': 0.5,\n",
    "#      'colsample_bylevel': 1,\n",
    "#      'colsample_bytree': 1,\n",
    "#      'gamma': 0.4,\n",
    "#      'learning_rate': 0.015,\n",
    "#      'max_delta_step': 0,\n",
    "#      'max_depth': 3,\n",
    "#      'min_child_weight': 6,\n",
    "#      'missing': None,\n",
    "#      'n_estimators': 1000,\n",
    "#      'nthread': -1,\n",
    "#      'objective': 'binary:logistic',\n",
    "#      'reg_alpha': 10,\n",
    "#      'reg_lambda': 0.5,\n",
    "#      'scale_pos_weight': 1,\n",
    "#      'seed': 0,\n",
    "#      'silent': True,\n",
    "#      'subsample': 1}\n",
    "\n",
    "\n",
    "clf.set_params(**params)\n",
    "\n",
    "pred_proba_on_data = make_classification(featured_data, y, clf, scaler,\n",
    "                                         test_size=0.25, show_feat_imp='xgb', \n",
    "                                         make_cv=True, cv_folds=5, show_class=1, prob_thres=0.5)\n",
    "\n",
    "telegram_send.send(messages=['Classifier fit_predict ended!',], \n",
    "                   conf=r'C:\\Users\\shumilkinayu\\Documents\\tg_notification.conf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_selection(featured_data, y, model, scaler, params):\n",
    "    thresholds = np.sort(np.unique(model.feature_importances_))\n",
    "    model = clf\n",
    "    scores = []\n",
    "    mx_id = 0\n",
    "\n",
    "    X = scaler.fit_transform(featured_data)\n",
    "    \n",
    "    for thresh, i in zip(thresholds, range(thresholds.shape[0])):\n",
    "        selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "        select_X = selection.transform(X)\n",
    "\n",
    "        selection_model = XGBClassifier()\n",
    "        selection_model.set_params(**params)\n",
    "\n",
    "        X_overs = select_X.copy()\n",
    "        y_overs = y.copy()\n",
    "        oversampling(X_overs, y_overs)\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        cv_score = cross_val_score(selection_model, X_overs, y_overs, scoring='roc_auc', cv=3)\n",
    "        if i % 10 == 0:\n",
    "            print('step', i)\n",
    "        scores.append(cv_score.mean())\n",
    "        if scores[i - 1] > scores[mx_id]:\n",
    "            mx_id = i - 1\n",
    "            \n",
    "    print(thresholds[mx_id], scores[mx_id])\n",
    "    a = (clf.feature_importances_ >= thresholds[mx_id])\n",
    "    telegram_send.send(messages=['Score after feat. sel.: ' + str(scores[mx_id]),], \n",
    "                   conf=r'C:\\Users\\shumilkinayu\\Documents\\tg_notification.conf')\n",
    "    print(featured_data.columns[a].shape)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {'base_score': 0.5,\n",
    "     'colsample_bylevel': 1,\n",
    "     'colsample_bytree': 1,\n",
    "     'gamma': 0.4,\n",
    "     'learning_rate': 0.15,\n",
    "     'max_delta_step': 0,\n",
    "     'max_depth': 3,\n",
    "     'min_child_weight': 6,\n",
    "     'missing': None,\n",
    "     'n_estimators': 100,\n",
    "     'nthread': -1,\n",
    "     'objective': 'binary:logistic',\n",
    "     'reg_alpha': 10,\n",
    "     'reg_lambda': 0.5,\n",
    "     'scale_pos_weight': 1,\n",
    "     'seed': 0,\n",
    "     'silent': True,\n",
    "     'subsample': 1}\n",
    "\n",
    "telegram_send.send(messages=['Feature selection began',], \n",
    "                   conf=r'C:\\Users\\shumilkinayu\\Documents\\tg_notification.conf')\n",
    "compreh_good_feats = feature_selection(featured_data, y, clf, scaler, params)\n",
    "telegram_send.send(messages=['Feature selection end!',], \n",
    "                   conf=r'C:\\Users\\shumilkinayu\\Documents\\tg_notification.conf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model params tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class ParametersTuner:\n",
    "    '''Tuning parameters for XGBoost step by step.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    validation_set : matrix, shape = [n_samples, n_features]\n",
    "    Featured object set for validate parameters\n",
    "    \n",
    "    y : array, shape = [n_samples, 1]\n",
    "    Labels for validation_set\n",
    "    \n",
    "    test_params_lists : dict with list values\n",
    "    Dictionarty with list of xgb parameters for Grid Search validate on\n",
    "    \n",
    "    base_params : dict \n",
    "    Dictionary with base params for XGboost\n",
    "    \n",
    "    scoring : string, default='roc_auc'\n",
    "    Sklearn metric in Grid Search view for score parameters\n",
    "    \n",
    "    cv : integer or cross-validation generator, default=3,\n",
    "    If integer, it is number of cv folds. \n",
    "    Else cv. \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, validation_set, y, test_params_lists,\n",
    "                 base_params, scoring='roc_auc', cv=3):\n",
    "        \n",
    "        self.test_params_lists = {\n",
    "            'learning_rate' : [0.005, 0.01, 0.1, 0.2, 0.5],\n",
    "            'n_estimators' : [50, 100, 500, 1000],\n",
    "            'max_depth' : [2, 3, 5, 10],\n",
    "            'min_child_weight':[1, 2, 3, 6],\n",
    "            'gamma' : [i / 10.0 for i in range(0,5)],\n",
    "            'reg_alpha' : [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000],\n",
    "            'reg_lambda' : [0.001, 0.01, 0.1, 0.5, 1, 10, 50, 100, 1000],\n",
    "            'seed' : 0\n",
    "        }\n",
    "        self.test_params_lists.update(test_params_lists)\n",
    "        \n",
    "        self.val_set = validation_set\n",
    "        self.y = y\n",
    "        self.model_params = base_params\n",
    "        self.model = XGBClassifier()\n",
    "        self.scoring = scoring\n",
    "        self.cv = cv\n",
    "    \n",
    "    def _make_grid_search_and_param_change(self, test_params):\n",
    "        \n",
    "        grid_search = GridSearchCV(estimator=self.model, param_grid=test_params, \n",
    "                                   scoring=self.scoring, iid=False, cv=self.cv, verbose=10)\n",
    "        grid_search.fit(self.val_set, self.y)\n",
    "                         \n",
    "        print('Best params:', grid_search.best_params_,\n",
    "              'Score:', grid_search.best_score_)\n",
    "        print()\n",
    "        \n",
    "        for key, val in grid_search.best_params_.items():\n",
    "            self.model_params[key] = val\n",
    "        self.model.set_params(**self.model_params)\n",
    "    \n",
    "    def make_tuning(self):\n",
    "    \n",
    "        steps = {\n",
    "            '1. RATE' : ['learning_rate'],\n",
    "            '2. N_OF_EST' : ['n_estimators'],\n",
    "            '3. TREE_PARAMS' : ['min_child_weight', 'max_depth', 'gamma'],\n",
    "            '4. REGURALIZATION' : ['reg_alpha', 'reg_lambda']\n",
    "        }\n",
    "        \n",
    "        for step, param_names in steps.items():\n",
    "            print('--------STEP: {}--------'.format(step))\n",
    "            test_params = dict(zip(steps[step], \n",
    "                                   [self.test_params_lists[key] \n",
    "                                    for key in steps[step]]))\n",
    "            print('],\\n'.join(str(test_params).split('],')))\n",
    "            self._make_grid_search_and_param_change(test_params)\n",
    "             \n",
    "        step = '5. REDUCE RATE' \n",
    "        print('--------STEP {}--------'.format(step))\n",
    "        test_params = {'learning_rate' : [self.model_params['learning_rate'], \n",
    "                                                              self.model_params['learning_rate'] / 10],\n",
    "                                           'n_estimators' : [self.model_params['n_estimators'], \n",
    "                                                             self.model_params['n_estimators'] * 10]}\n",
    "        print('],\\n'.join(str(test_params).split('],')))\n",
    "        self._make_grid_search_and_param_change(test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_params = {\n",
    "            'learning_rate' : 0.01,\n",
    "            'n_estimators' : 100,\n",
    "            'max_depth' : 3,\n",
    "            'gamma' : 0,\n",
    "            'min_child_weight' : 1,\n",
    "            'reg_alpha' : 0,\n",
    "            'reg_lambda' : 1,\n",
    "            'seed' : 0\n",
    "        }\n",
    "\n",
    "params_list = {\n",
    "    'learning_rate' : [0.2],\n",
    "    'n_estimators' : [100],\n",
    "    'max_depth' : [2, 3, 4, 5, 10],\n",
    "    'min_child_weight':[1, 2, 3, 4, 6],\n",
    "    'gamma' : [i / 10.0 for i in range(0,5)],\n",
    "    'reg_alpha' : [0.01, 0.1, 0.5, 1, 1.5, 10, 30, 50, 100, 1000],\n",
    "    'reg_lambda' : [0.01, 0.1, 0.5, 1, 1.5, 10, 30, 50, 100, 1000],\n",
    "    'seed' : 0\n",
    "}\n",
    "\n",
    "scaler = StandardScaler()\n",
    "tuner = ParametersTuner(scaler.fit_transform(featured_data[featured_data.columns[compreh_good_feats]]), \n",
    "                        y, params_list, base_params)\n",
    "tuner.make_tuning()\n",
    "tuner.model.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
